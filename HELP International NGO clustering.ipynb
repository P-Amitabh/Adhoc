{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Clustering Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Import the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 1: Reading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "from math import isnan\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Countries file\n",
    "\n",
    "df_country = pd.read_csv('Country-data.csv')\n",
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data dictionary\n",
    "\n",
    "country_dict = pd.read_csv('data-dictionary+.csv')\n",
    "country_dict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the data\n",
    "\n",
    "df_country.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the statistics of the numerical values\n",
    "\n",
    "df_country.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data types\n",
    "\n",
    "df_country.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the missing values\n",
    "\n",
    "df_country.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - No missing values were found in any of the columns\n",
    "##### - Datatypes also all seem to be consistent\n",
    "##### - No cleaning seems to be requried as data seems to be good enough to proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 3: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the correlation of the various factor in the dataset\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "sns.heatmap(df_country.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - gdpp and income are highly correlated\n",
    "##### - Exports and imports are also highly correlated\n",
    "##### - life expectancy and income are highly correlated\n",
    "##### - total fertility and life expectancy are inversely correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_country)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 4: Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Some column values such as imports, exports and health spend are percentage values and thus aren't very useful. Therefore we'll need to convert them into absolute values to further deduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the imports, exports and health columns to absolute values\n",
    "\n",
    "df_country['imports'] = df_country['imports']*df_country['gdpp']/100\n",
    "df_country['exports'] = df_country['exports']*df_country['gdpp']/100\n",
    "df_country['health'] = df_country['health']*df_country['gdpp']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the country, before proceeding towards re-scaling the features\n",
    "\n",
    "df_country_drop = df_country.copy()\n",
    "country = df_country_drop.pop('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scaling of features within the dataframe\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_country_scaled = scaler.fit_transform(df_country_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen in the below array the features have now been scaled\n",
    "\n",
    "df_country_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 5: Principal Component Analysis or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA is being done to remove redundancies and the attributes that are highly correlated\n",
    "\n",
    "pca = PCA(svd_solver = 'randomized', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(df_country_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see components for PCA have been created\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the variance ratio for PCA\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barplot for PCA components varianca ratio\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_)+1),pca.explained_variance_ratio_)\n",
    "plt.xlabel('Components of PCA')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As seen above, component one has a variance of almost 0.6\n",
    "##### - The second component variance is almost 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the best explained pca components\n",
    "\n",
    "col_type = list(df_country.drop(['country'], axis = 1).columns)\n",
    "attributes_pca = pd.DataFrame({'Attribute':col_type, 'Comp_1':pca.components_[0], 'Comp_2':pca.components_[1], 'Comp_3':pca.components_[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll visualise the above dataset with a plot for Comp_1 and Comp_2\n",
    "\n",
    "sns.pairplot(data = attributes_pca, x_vars = ['Comp_1'], y_vars = ['Comp_2'], hue = 'Attribute', height = 8)\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "\n",
    "for i,txt in enumerate(attributes_pca.Attribute):\n",
    "    plt.annotate(txt, (attributes_pca.Comp_1[i],attributes_pca.Comp_2[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Child mortality and total fertility are very well explained by Comp_1\n",
    "##### - gdpp, health, income and life expectancy are well explained by Comp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll visualise the above dataset with a plot for Comp_1 and Comp_3\n",
    "\n",
    "sns.pairplot(data = attributes_pca, x_vars = ['Comp_1'], y_vars = ['Comp_3'], hue = 'Attribute', height = 8)\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 3')\n",
    "\n",
    "for i,txt in enumerate(attributes_pca.Attribute):\n",
    "    plt.annotate(txt, (attributes_pca.Comp_1[i],attributes_pca.Comp_3[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Inflation in best explained by Comp_3\n",
    "##### - As we can see from the above plots, more than 90% of the variance is explained well by the three components. We will build the dataframe with these components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on self done research, we have understood that incremental PCA grants better efficiency.\n",
    "\n",
    "incre_pca = IncrementalPCA(n_components = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll fit the incremental pca on the scaled df\n",
    "\n",
    "df_incre_pca = incre_pca.fit_transform(df_country_scaled)\n",
    "df_incre_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new dataframe with the principal components\n",
    "\n",
    "df_pca = pd.DataFrame(df_incre_pca, columns = ['Comp_1','Comp_2','Comp_3'])\n",
    "df_pca_final = pd.concat([country, df_pca], axis = 1)\n",
    "df_pca_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for dependancy in the dataset\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(df_pca_final.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As we can see above the correlation is almost non-existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for spread of data across the components\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.scatterplot(data = df_pca_final, x = 'Comp_1', y = 'Comp_2')\n",
    "plt.subplot(1,3,2)\n",
    "sns.scatterplot(data = df_pca_final, x = 'Comp_1', y = 'Comp_3')\n",
    "plt.subplot(1,3,3)\n",
    "sns.scatterplot(data = df_pca_final, x = 'Comp_3', y = 'Comp_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Analysis\n",
    "\n",
    "outliers = ['Comp_1','Comp_2','Comp_3']\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "sns.boxplot(data = df_pca_final[outliers])\n",
    "plt.title('Distribution of outlier variables')\n",
    "plt.xlabel('PC Components')\n",
    "plt.ylabel('Range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statstical Outlier treatment for PC_1\n",
    "\n",
    "Q1 = df_pca_final.Comp_1.quantile(0.05)\n",
    "Q3 = df_pca_final.Comp_1.quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "df_pca_final = df_pca_final[(df_pca_final.Comp_1 >= Q1) & (df_pca_final.Comp_1 <= Q3)]\n",
    "\n",
    "# Statstical Outlier treatment for PC_2\n",
    "\n",
    "Q1 = df_pca_final.Comp_2.quantile(0.05)\n",
    "Q3 = df_pca_final.Comp_2.quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "df_pca_final = df_pca_final[(df_pca_final.Comp_2 >= Q1) & (df_pca_final.Comp_2 <= Q3)]\n",
    "\n",
    "# Statstical Outlier treatment for PC_3\n",
    "\n",
    "Q1 = df_pca_final.Comp_3.quantile(0.05)\n",
    "Q3 = df_pca_final.Comp_3.quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "df_pca_final = df_pca_final[(df_pca_final.Comp_3 >= Q1) & (df_pca_final.Comp_3 <= Q3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ['Comp_1','Comp_2','Comp_3']\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "sns.boxplot(data = df_pca_final[outliers])\n",
    "plt.title('Distribution of outlier variables')\n",
    "plt.xlabel('PC Components')\n",
    "plt.ylabel('Range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index after outlier removal\n",
    "\n",
    "df_pca_final = df_pca_final.reset_index(drop = True)\n",
    "df_pca_final_data = df_pca_final.drop(['country'],axis=1)\n",
    "df_pca_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 6: Hopkins Statistic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use this test to determine if the data is good enough for clustering\n",
    "\n",
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    n = len(X)\n",
    "    m = int(0.1*n)\n",
    "    nbrs = NearestNeighbors(n_neighbors = 1).fit(X.values)\n",
    "    \n",
    "    rand_X = sample(range(0,n,1), m)\n",
    "    \n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(0,m):\n",
    "        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    "        \n",
    "        HS = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "        if isnan(HS):\n",
    "            print(ujd, wjd)\n",
    "            HS = 0\n",
    "            \n",
    "        return HS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hopkins score for the data\n",
    "\n",
    "hopkins(df_pca_final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 7: Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will first start with using K-means clustering\n",
    "#Elbow curve method is to be used here to help attain the optimal value for k\n",
    "\n",
    "ssd = []\n",
    "for num_clusters in list(range(1,8)):\n",
    "    model_clus = KMeans(n_clusters = num_clusters, max_iter=50,random_state= 100)\n",
    "    model_clus.fit(df_pca_final_data)\n",
    "    ssd.append(model_clus.inertia_)\n",
    "\n",
    "plt.plot(ssd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As we can see from the above elbow curve, the number of clusters should be 4 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also do a silhouette score analysis to determine the ideal number of clusters\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "for num_clusters in range_n_clusters:\n",
    "    \n",
    "    #intialise kmeans\n",
    "    kmeans = KMeans(n_clusters=num_clusters, max_iter=50,random_state= 100)\n",
    "    kmeans.fit(df_pca_final_data)\n",
    "    \n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    #silhouette score\n",
    "    silhouette_avg = silhouette_score(df_pca_final_data, cluster_labels)\n",
    "    \n",
    "    print('If number of clusters = {0}, the silhouette score will be {1}'.format(num_clusters, silhouette_avg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Now we can check kmeans with k = 4\n",
    "\n",
    "cluster4 = KMeans(n_clusters = 4, max_iter = 50, random_state = 100)\n",
    "cluster4.fit(df_pca_final_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Getting and assigning cluster labels\n",
    "\n",
    "cluster4.labels_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_pca_final['Cluster_Id4'] = cluster4.labels_\n",
    "df_pca_final.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Finding out the number of countries in each cluster\n",
    "\n",
    "df_pca_final['Cluster_Id4'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### - The clusters seem to be well defined"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Plotting a scatterplot to visualise the spread of the data\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_2', hue = 'Cluster_Id4', data = df_pca_final, ax = axes[0], palette = 'Set1')\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_3', hue = 'Cluster_Id4', data = df_pca_final, ax = axes[1], palette = 'Set1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### - Plot 1 seems to have high intra-cluster distance which is not a good sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what happens when we change the number of clusters to 5\n",
    "\n",
    "cluster5 = KMeans(n_clusters = 5, max_iter = 50, random_state = 100)\n",
    "cluster5.fit(df_pca_final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels for cluster5\n",
    "\n",
    "cluster5.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning labels\n",
    "\n",
    "df_pca_final['Cluster_Id'] = cluster5.labels_\n",
    "df_pca_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding out the number of countries in each cluster\n",
    "\n",
    "df_pca_final['Cluster_Id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Each of the clusters seem to have a good number of countries present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a scatterplot to visualise the spread of the data\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (15,8))\n",
    "\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_2', hue = 'Cluster_Id', data = df_pca_final, ax = axes[0], palette = 'Set1')\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_3', hue = 'Cluster_Id', data = df_pca_final, ax = axes[1], palette = 'Set1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As we can see above we have run into the same issue as with k=4. But since we have another segment, we can proceed with 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let'try to visualise the data on the original attributes\n",
    "\n",
    "df_merge = pd.merge(df_country, df_pca_final, on = 'country')\n",
    "df_merge_col = df_merge[['country','child_mort','exports','imports','health','income','inflation','life_expec','total_fer','gdpp','Cluster_Id']]\n",
    "\n",
    "cluster_child = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).child_mort.mean())\n",
    "cluster_export = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).exports.mean())\n",
    "cluster_import = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).imports.mean())\n",
    "cluster_health = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).health.mean())\n",
    "cluster_income = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).income.mean())\n",
    "cluster_inflation = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).inflation.mean())         \n",
    "cluster_lifeexpec = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).life_expec.mean())\n",
    "cluster_totalfer = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).total_fer.mean())\n",
    "cluster_gdpp = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).gdpp.mean())\n",
    "\n",
    "df_concat = pd.concat([pd.Series([0,1,2,3,4]),cluster_child,cluster_export,cluster_import,cluster_health,cluster_income\n",
    "                       ,cluster_inflation,cluster_lifeexpec,cluster_totalfer,cluster_gdpp], axis=1)\n",
    "df_concat.columns = [\"Cluster_Id\", \"Child_Mortality\", \"Exports\", \"Imports\",\"Health_Spending\",\"Income\",\"Inflation\",\"Life_Expectancy\",\"Total_Fertility\",\"GDPpcapita\"]\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a scatterplot to visualise the spread of the original attributes\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize = (15,10))\n",
    "\n",
    "sns.scatterplot(x = 'income', y = 'child_mort',hue='Cluster_Id',data = df_merge_col,legend='full',palette=\"Set1\",ax=axes[0])\n",
    "sns.scatterplot(x = 'gdpp', y = 'income',hue='Cluster_Id', data = df_merge_col,legend='full',palette=\"Set1\",ax=axes[1])\n",
    "sns.scatterplot(x = 'child_mort', y = 'gdpp',hue='Cluster_Id', data=df_merge_col,legend='full',palette=\"Set1\",ax=axes[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also plot a boxplot on the original attributes\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize = (15,10))\n",
    "\n",
    "sns.boxplot(x = 'Cluster_Id', y = 'child_mort', data = df_merge_col, ax = axes[0][0])\n",
    "sns.boxplot(x = 'Cluster_Id', y = 'income', data = df_merge_col, ax = axes[0][1])\n",
    "sns.boxplot(x = 'Cluster_Id', y = 'inflation', data = df_merge_col, ax = axes[1][0])\n",
    "sns.boxplot(x = 'Cluster_Id', y = 'gdpp', data = df_merge_col, ax = axes[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Child mortality is highest in clusters 1 and 4. They will require aid.\n",
    "##### - A high income and high gdpp are indicators of a well developed country.\n",
    "##### - As seen above countries in clusters 1 and 4 have the lowest income and gdpp and will therefor require monetary assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the countries in cluster 1\n",
    "\n",
    "df_merge_col[df_merge_col['Cluster_Id']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the countries in cluster 4\n",
    "\n",
    "df_merge_col[df_merge_col['Cluster_Id']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try hierarchical clustering and see if the results differ\n",
    "#As we know there are two types of hierarchical clustering, divisive and agglomerative.\n",
    "\n",
    "df_pca_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's begin with single linkage\n",
    "\n",
    "merging = linkage(df_pca_final_data, method = 'single', metric = 'euclidean')\n",
    "dendrogram(merging)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also try complete linkage\n",
    "\n",
    "merging = linkage(df_pca_final_data, method = 'complete', metric = 'euclidean')\n",
    "dendrogram(merging)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_hclus = df_pca_final.copy()\n",
    "df_pca_hclus = df_pca_hclus.drop('Cluster_Id', axis = 1)\n",
    "df_pca_hclus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get a better cluster formation, we can cut the tree at height of 3.\n",
    "\n",
    "cluster_cut = pd.Series(cut_tree(merging, n_clusters = 4).reshape(-1,))\n",
    "df_hclus = pd.concat([df_pca_hclus, cluster_cut], axis = 1)\n",
    "df_hclus.columns = ['country', 'Comp_1', 'Comp_2','Comp_3','Cluster_Id']\n",
    "df_hclus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a scatterplot to visualise the spread of the principal components\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_2', hue = 'Cluster_Id', data = df_hclus, ax = axes[0], palette = 'Set1')\n",
    "sns.scatterplot(x = 'Comp_1', y = 'Comp_3', hue = 'Cluster_Id', data = df_hclus, ax = axes[1], palette = 'Set1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As seen above the fourth cluster has not properly formed in the first plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the original dataframe with the dataframe containing PCA\n",
    "\n",
    "df_merge_hclus = pd.merge(df_country, df_hclus, on = 'country')\n",
    "df_merge_hclus_col = df_merge[['country','child_mort','exports','imports','health','income','inflation','life_expec','total_fer','gdpp','Cluster_Id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_hclus_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a scatterplot to visualise the spread of the original attributes\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize = (15,10))\n",
    "\n",
    "sns.scatterplot(x = 'income', y = 'child_mort',hue='Cluster_Id',data = df_merge_hclus_col,legend='full',palette=\"Set1\",ax=axes[0])\n",
    "sns.scatterplot(x = 'gdpp', y = 'income',hue='Cluster_Id', data = df_merge_hclus_col,legend='full',palette=\"Set1\",ax=axes[1])\n",
    "sns.scatterplot(x = 'child_mort', y = 'gdpp',hue='Cluster_Id', data= df_merge_hclus_col,legend='full',palette=\"Set1\",ax=axes[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - After analyzing using both methods. We can see that the clusters have formed better using K-means. Using which we'll obtain the final list of countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Step 8: Final Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As seen above we have identified that cluster 1 and 4 are in need of aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus1 = df_merge_col[df_merge_col['Cluster_Id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus4 = df_merge_col[df_merge_col['Cluster_Id'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arriving at the list of countries which require aid\n",
    "\n",
    "df_append = df_clus1.append(df_clus4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing the numerical columns within the dataframe\n",
    "\n",
    "df_append.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the above information we can see that the mean child_mort is 52 for the selected clusters\n",
    "#We can take all the countries with child_mort greater than the mean, 52.\n",
    "\n",
    "df_final_list = df_country[df_country['child_mort'] > 52]\n",
    "df_final_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the demographic again\n",
    "\n",
    "df_final_list.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen above the mean income is 3855, we can take all countries which fall below that\n",
    "\n",
    "df_final_list1 = df_final_list[df_final_list['income'] <= 3855]\n",
    "df_final_list1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the demographic once again\n",
    "\n",
    "df_final_list1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen above mean gdpp is 833, we can take all countries which fall below\n",
    "\n",
    "df_final_list2 = df_final_list1[df_final_list1['gdpp'] <= 833]\n",
    "df_final_list2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence we arrive at the final list of countries which require aid based on the selected socio-economic factors\n",
    "\n",
    "df_final_list2['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the data for countries which need aid based on child mortality\n",
    "\n",
    "df_list_cm = pd.DataFrame(df_final_list2.groupby(['country'])['child_mort'].mean().sort_values(ascending = False))\n",
    "\n",
    "df_list_cm.plot.bar()\n",
    "plt.title('Aid based on child mortality by country')\n",
    "plt.xlabel('Country', fontweight = 'bold')\n",
    "plt.ylabel('Child Mortality', fontweight = 'bold', fontsize = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the data for countries which need aid based on per capita income\n",
    "\n",
    "df_list_cm = pd.DataFrame(df_final_list2.groupby(['country'])['income'].mean().sort_values(ascending = False))\n",
    "\n",
    "df_list_cm.plot.bar()\n",
    "plt.title('Aid based on per capita income by country')\n",
    "plt.xlabel('Country', fontweight = 'bold')\n",
    "plt.ylabel('Per capita income', fontweight = 'bold', fontsize = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the data for countries which need aid based on gdpp\n",
    "\n",
    "df_list_cm = pd.DataFrame(df_final_list2.groupby(['country'])['gdpp'].mean().sort_values(ascending = False))\n",
    "\n",
    "df_list_cm.plot.bar()\n",
    "plt.title('Aid based on gdpp by country')\n",
    "plt.xlabel('Country', fontweight = 'bold')\n",
    "plt.ylabel('gdpp', fontweight = 'bold', fontsize = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Conclusion\n",
    "\n",
    "##### - As can be seen above PCA was done to get rid of redundant variables. After which we did clustering of countries based on the PCA components. We also verified socio-economic factors such as Child Mortality, Income and GDPP. These factors place a vital role in determining the development within the country. Clusters were built using this information. Using these clusters we were able to derive the final list of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final list of countries that require aid\n",
    "\n",
    "df_final_list2.reset_index(drop = True)['country']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
