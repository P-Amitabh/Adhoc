{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Sharing Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Suppress warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting display options\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Reading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'day.csv' file and saving it in the variable ''\n",
    "\n",
    "bike_sharing = pd.read_csv('day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data\n",
    "\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns for easier understanding\n",
    "\n",
    "bike_sharing.rename(columns = {'yr':'year','mnth':'month','temp':'temperature','hum':'humidity','cnt':'count'}, inplace = True)\n",
    "\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the dataframe\n",
    "\n",
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of numeric columns\n",
    "\n",
    "bike_sharing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the datatypes of each column\n",
    "\n",
    "bike_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a check for null values\n",
    "# As seen below, there aren't any null values present\n",
    "\n",
    "bike_sharing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping categorical columns with their categories as given in the data dictionary\n",
    "\n",
    "bike_sharing['season'] = bike_sharing['season'].map({1: 'Spring', 2: 'Summer',3:'Fall', 4:'Winter' })\n",
    "\n",
    "bike_sharing['month'] = bike_sharing['month'].map({1:'January',2:'February',3:'March',4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'})\n",
    "\n",
    "bike_sharing['weathersit'] = bike_sharing['weathersit'].map({1: 'Clear',2:'Mist + Cloudy',3:'Light Snow',4:'Snow + Fog'})\n",
    "\n",
    "bike_sharing['weekday'] = bike_sharing['weekday'].map({0:'Sunday',1:'Monday',2:'Tuesday',3:'Wednesday',4:'Thursday',5:'Friday',6:'Saturday'})\n",
    "\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the categorical and continuous columns\n",
    "\n",
    "bike_sharing.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As per my understanding based on the learning from the modules,\n",
    "##### - Columns with values less than or equal to 40 are considered categorical\n",
    "##### - Columns with values greater than 40 are considered continuous\n",
    "##### - Sorting values in ascending order for easier readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can begin visualising the data for better understanding\n",
    "# Visualising numerical columns using a pairplot\n",
    "\n",
    "sns.pairplot(bike_sharing, vars = ['temperature','humidity','casual','windspeed','registered','atemp','count','instant'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - By analysing the above pairplot we can see that some variables have a positive correlation to the count variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualing the 7 categorical variables, we'll be using boxplots for this\n",
    "\n",
    "plt.figure(figsize = (30, 15))\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "sns.boxplot(x = 'year', y = 'count', data = bike_sharing)\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "sns.boxplot(x = 'holiday', y = 'count', data = bike_sharing)\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "sns.boxplot(x = 'workingday', y = 'count', data = bike_sharing)\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "sns.boxplot(x = 'month', y = 'count', data = bike_sharing)\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "sns.boxplot(x = 'season', y = 'count', data = bike_sharing)\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "sns.boxplot(x = 'weekday', y = 'count', data = bike_sharing)\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "sns.boxplot(x = 'weathersit', y = 'count', data = bike_sharing)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Bike rentals were considerably higher in 2019\n",
    "##### - Bike rentals were higher during days which weren't holidays, indicating people use bikes for more than just leisure\n",
    "##### - Bike rentals were much higher during the fall months\n",
    "##### - Clear weather was the most preferred for bike rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Taking a better look at the individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year\n",
    "# 0:2018, 1:2019\n",
    "# Rentals largest in 2019\n",
    "\n",
    "sns.barplot('year', 'count', data = bike_sharing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.barplot('month', 'count',hue = 'year', data = bike_sharing)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season\n",
    "# Highest rentals in fall\n",
    "\n",
    "sns.barplot('season', 'count', data = bike_sharing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weathersit\n",
    "# Clear weather preferred\n",
    "\n",
    "sns.barplot('weathersit', 'count', data = bike_sharing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Humidity\n",
    "# Higher the humidity, higher the number of bikes rented\n",
    "\n",
    "sns.scatterplot(x = 'humidity', y = 'count', data = bike_sharing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "\n",
    "sns.scatterplot(x = 'temperature', y = 'count', data = bike_sharing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation of variables using a heatmap\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(bike_sharing.corr(), cmap = 'Reds', annot = True)\n",
    "plt.title('Correlation between individuals variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - instant, year, temperature, atemp, casual, registered are all highly correlated to count.\n",
    "##### - A couple of other variables are also higly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "# instant dropped as its the unique value for each row\n",
    "# dteday dropped as information already captured\n",
    "# atemp dropped as highly correlated with temperature\n",
    "# casual and registered dropped as they form the total, which is count\n",
    "\n",
    "bike_sharing = bike_sharing.drop(['instant','dteday','atemp','casual','registered'], axis = 1)\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for weathersit, month, weekday, season\n",
    "# We'll also be dropping the first column\n",
    "\n",
    "weather_sit = pd.get_dummies(bike_sharing['weathersit'], drop_first = True)\n",
    "months = pd.get_dummies(bike_sharing['month'], drop_first = True)\n",
    "weekdays = pd.get_dummies(bike_sharing['weekday'], drop_first = True)\n",
    "seasons = pd.get_dummies(bike_sharing['season'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the dummy variables to the original dataframe\n",
    "\n",
    "bike_sharing = pd.concat([weather_sit,months,weekdays,seasons, bike_sharing], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping weather_sit,months,weekdays,seasons as the dummy variables for these have been created\n",
    "\n",
    "bike_sharing.drop(['weathersit','month','weekday','season'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape\n",
    "\n",
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlation of the updated dataframe\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "sns.heatmap(bike_sharing.corr(), cmap = 'Reds', annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - From the above heatmap we can see that the months ranging from may to october, the summer season and temperature have a strong correlation with the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Dividing the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "\n",
    "bike_sharing_train, bike_sharing_test = train_test_split(bike_sharing, train_size = 0.7, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape after split\n",
    "\n",
    "print(bike_sharing_train.shape)\n",
    "print(bike_sharing_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "# Methods to be used, standardization or normalisation via Min-Max scaling\n",
    "# This is done so that the obtained coefficients are all on the same scale\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Creating a list of numeric variables\n",
    "\n",
    "num_vars = ['temperature','humidity','windspeed','count']\n",
    "\n",
    "# Fitting on data\n",
    "\n",
    "bike_sharing_train[num_vars] = scaler.fit_transform(bike_sharing_train[num_vars])\n",
    "bike_sharing_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the variables after scaling\n",
    "# All numeric variables are now between 0 and 1\n",
    "\n",
    "bike_sharing_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation on the train\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "sns.heatmap(bike_sharing_train.corr(), cmap = 'Reds', annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As seen above there is very little to no collinearity between the variables\n",
    "##### - The highest correlation is between the count variable, year and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data into X and y sets\n",
    "# Removing the target variable from y_train\n",
    "\n",
    "y_train = bike_sharing_train.pop('count')\n",
    "X_train = bike_sharing_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Bulding the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by using RFE or Recursive Feature Elimination\n",
    "# Setting the output number to 15 variables as per what was indicated during the session\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Running RFE \n",
    "\n",
    "rfe = RFE(lm, 15)\n",
    "rfe = rfe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables selected\n",
    "\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE true columns\n",
    "\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE false columns\n",
    "\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Using statsmodel, for getting the summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test dataframe with the selected variables\n",
    "\n",
    "X_train_rfe = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the constant variable\n",
    "\n",
    "X_train_rfe = sm.add_constant(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "\n",
    "lm = sm.OLS(y_train, X_train_rfe).fit()\n",
    "\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant\n",
    "\n",
    "X_train_rfe = X_train_rfe.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_rfe\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - January can be dropped as it has a high p-value and a low VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping January\n",
    "\n",
    "X_train_new = X_train_rfe.drop(['January'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model without January\n",
    "\n",
    "X_train_lm1 = sm.add_constant(X_train_new)\n",
    "lm1 = sm.OLS(y_train, X_train_lm1).fit()\n",
    "print(lm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the constant as well\n",
    "\n",
    "X_train_lm1 = X_train_lm1.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting new VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Dropping humidity due to high VIF and low p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping humidity\n",
    "\n",
    "X_train_new2 = X_train_lm1.drop(['humidity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model without humidity\n",
    "\n",
    "X_train_lm2 = sm.add_constant(X_train_new2)\n",
    "lm2 = sm.OLS(y_train, X_train_lm2).fit()\n",
    "print(lm2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant\n",
    "\n",
    "X_train_lm2 = X_train_lm2.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting new VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new2\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Dropping holiday due to low p-value and high VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping holiday\n",
    "\n",
    "X_train_new3 = X_train_lm2.drop(['holiday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model without holiday\n",
    "\n",
    "X_train_lm3 = sm.add_constant(X_train_new3)\n",
    "lm3 = sm.OLS(y_train, X_train_lm3).fit()\n",
    "print(lm3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant\n",
    "\n",
    "X_train_lm3 = X_train_lm3.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting new VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new3\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Windspeed can be dropped due to high VIF and inverse correlation to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping windspeed\n",
    "\n",
    "X_train_new4 = X_train_lm3.drop(['windspeed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model without windspeed\n",
    "\n",
    "X_train_lm4 = sm.add_constant(X_train_new4)\n",
    "lm4 = sm.OLS(y_train, X_train_lm4).fit()\n",
    "print(lm4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant\n",
    "\n",
    "X_train_lm4 = X_train_lm4.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting new VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new4\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Dropping July based on low p-value and low VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping July\n",
    "\n",
    "X_train_new5 = X_train_lm4.drop(['July'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model without windspeed\n",
    "\n",
    "X_train_lm5 = sm.add_constant(X_train_new5)\n",
    "lm5 = sm.OLS(y_train, X_train_lm5).fit()\n",
    "print(lm5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant\n",
    "\n",
    "X_train_lm5 = X_train_lm5.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting new VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new5\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = 'VIF', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As we can see that all VIFs and p-values are acceptable, this will now be the model.\n",
    "##### - The final model, X_train_lm5 was obtained by dropping January, July, humidity, holiday and windspeed variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do this analysis to check for normal distribution of the error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our model\n",
    "\n",
    "X_train_lm5 = sm.add_constant(X_train_lm5)\n",
    "X_train_lm5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y pred training set\n",
    "\n",
    "y_train_pred = lm5.predict(X_train_lm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking normal distribution of error terms\n",
    "\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "plt.title('Error terms distribution')\n",
    "plt.xlabel('Error values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - As seem above the error terms are normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing scaling for numeric variables\n",
    "\n",
    "num_vars = ['temperature','humidity','windspeed','count']\n",
    "\n",
    "# Fitting on data\n",
    "\n",
    "bike_sharing_test[num_vars] = scaler.transform(bike_sharing_test[num_vars])\n",
    "bike_sharing_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing test set into X and y\n",
    "\n",
    "y_test = bike_sharing_test.pop('count')\n",
    "X_test = bike_sharing_test\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lm5 = X_train_lm5.drop(['const'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lm5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to make predictions\n",
    "\n",
    "X_test_new = X_test[X_train_lm5.columns]\n",
    "\n",
    "# Adding a constant\n",
    "\n",
    "X_test_new1 = sm.add_constant(X_test_new)\n",
    "X_test_new1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to make predictions\n",
    "\n",
    "y_pred = lm5.predict(X_test_new1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Calculating the R^2 and the Adjusted R^2 for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find R^2 for test set\n",
    "\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Adjusted R^2 for test set\n",
    "# Applying the formula below\n",
    "\n",
    "adj_r2 = 1 - (1 - 0.81150)*(11-1)/(11-1-1)\n",
    "print(adj_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the spread by plotting together y_test and y_pred\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.scatter(y_test, y_pred, color = 'Red')\n",
    "plt.xlabel('y_test', fontsize = 15)\n",
    "plt.ylabel('y_pred', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a regression plot to understand the fit on the test set\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.regplot(y_test, y_pred, line_kws = {'color': 'red'})\n",
    "plt.title('y_test vs y_pred', fontsize = 15)\n",
    "plt.xlabel('y_test', fontsize = 15)\n",
    "plt.ylabel('y_pred', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Best fit line equation, y = mx + c + e\n",
    "##### - Equation for the best fit line is as follows,\n",
    "#####   count = 0.49 x temperature + 0.09 x September + 0.06 x Saturday + 0.05 x Summer + 0.097 x Winter + 0.23 x year + 0.056 x workingday - 0.03 x lightsnow - 0.078 x mistcloudy - 0.065 x Spring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Train set R^2: 0.826\n",
    "##### - Train adj R^2: 0.822\n",
    "##### - Test set R^2: 0.8115\n",
    "##### - Test set adj R^2: 0.7905\n",
    "##### - Train and test R^2 difference: 1.5%\n",
    "##### - Train and test adj R^2 difference: 3.15%\n",
    "##### - Overall confirmed that the optimum model was obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - The variable temperature had the highest coefficient at 0.49, meaning that an increase of a single unit in temperature would lead to an increase in bike rentals by 0.49 units.\n",
    "##### - There were also some negative coefficents such as spring, mist + cloudy and light snow present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
